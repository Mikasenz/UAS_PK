================================================================================
📊 TAHAP 5 - MODEL EVALUATION - COMPREHENSIVE REPORT
================================================================================
Generated: 2025-06-26 08:30:37
Evaluation K-Value: 3
Models Evaluated: ['tfidf', 'bert', 'svm', 'naive_bayes']

🎯 EXECUTIVE SUMMARY
--------------------------------------------------
🏆 Best Performing Model: BERT
📈 Best F1-Score: 0.080
📝 Total Queries Evaluated: 10

📊 PERFORMANCE ANALYSIS
--------------------------------------------------

🔍 TFIDF SYSTEM:
   Precision: 0.033 ± 0.100
   Recall:    0.050 ± 0.150
   F1-Score:  0.040 ± 0.120
   Accuracy:  0.033
   Assessment: ⚠️ POOR

🔍 BERT SYSTEM:
   Precision: 0.067 ± 0.133
   Recall:    0.100 ± 0.200
   F1-Score:  0.080 ± 0.160
   Accuracy:  0.067
   Assessment: ⚠️ POOR

🔍 SVM SYSTEM:
   Precision: 0.033 ± 0.100
   Recall:    0.050 ± 0.150
   F1-Score:  0.040 ± 0.120
   Accuracy:  0.033
   Assessment: ⚠️ POOR

🔍 NAIVE_BAYES SYSTEM:
   Precision: 0.033 ± 0.100
   Recall:    0.050 ± 0.150
   F1-Score:  0.040 ± 0.120
   Accuracy:  0.033
   Assessment: ⚠️ POOR


🔍 FAILURE ANALYSIS
--------------------------------------------------

🔧 TFIDF FAILURES:
   Total Failures: 0
   Low Performance: 9
   Example Issues:
     - Q001: Low F1: 0.000
     - Q002: Low F1: 0.000

🔧 BERT FAILURES:
   Total Failures: 0
   Low Performance: 8
   Example Issues:
     - Q001: Low F1: 0.000
     - Q002: Low F1: 0.000

🔧 SVM FAILURES:
   Total Failures: 0
   Low Performance: 9
   Example Issues:
     - Q001: Low F1: 0.000
     - Q002: Low F1: 0.000

🔧 NAIVE_BAYES FAILURES:
   Total Failures: 0
   Low Performance: 9
   Example Issues:
     - Q001: Low F1: 0.000
     - Q002: Low F1: 0.000


📋 DETAILED METRICS TABLE
--------------------------------------------------
      Model  Queries Precision Recall F1-Score Accuracy  Std_Precision  Std_Recall  Std_F1
      TFIDF       10     0.033  0.050    0.040    0.033       0.100000        0.15    0.12
       BERT       10     0.067  0.100    0.080    0.067       0.133333        0.20    0.16
        SVM       10     0.033  0.050    0.040    0.033       0.100000        0.15    0.12
NAIVE_BAYES       10     0.033  0.050    0.040    0.033       0.100000        0.15    0.12


💡 RECOMMENDATIONS
--------------------------------------------------
🔧 CRITICAL IMPROVEMENTS NEEDED:
   - Increase dataset size (current: <200 cases)
   - Enhance vocabulary with legal domain terms
   - Improve text preprocessing for legal documents
   - Consider ensemble methods


🔬 TECHNICAL NOTES
--------------------------------------------------
   - Evaluation K-Value: 3
   - Dataset Size: Small (<200 cases)
   - Domain: Indonesian Legal Documents
   - Metrics: Standard IR metrics (P, R, F1)
   - Expected F1 Range: 0.15-0.35 for small legal datasets

================================================================================
📊 END OF EVALUATION REPORT
================================================================================