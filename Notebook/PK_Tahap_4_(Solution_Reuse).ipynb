{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i4VPfjzGsLX",
        "outputId": "19cd831d-2859-4103-f36f-67a0db4c9523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple, Optional, Counter\n",
        "from collections import Counter, defaultdict\n",
        "import logging\n",
        "\n",
        "# Machine Learning Libraries\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# BERT and Transformers\n",
        "try:\n",
        "    from transformers import AutoTokenizer, AutoModel\n",
        "    import torch\n",
        "    TRANSFORMERS_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Transformers not available. Install with: pip install transformers torch\")\n",
        "    TRANSFORMERS_AVAILABLE = False\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H6wX1MsHFDF",
        "outputId": "853dd1d4-6718-4e0a-eca6-fae267c46a1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ekstrak Solusi**"
      ],
      "metadata": {
        "id": "Px57MwtwHYT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i. EKSTRAK SOLUSI\n",
        "# 1. Dari kasus top-k, ambil amar putusan atau ringkasan dakwaan\n",
        "# 2. Simpan di struktur: {case_id: solusi_text}\n",
        "# ============================================================================\n",
        "\n",
        "class RetrievalSystem:\n",
        "    \"\"\"\n",
        "    Sistem retrieval untuk mendukung solution reuse\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/terorisme\"):\n",
        "        self.base_dir = base_dir\n",
        "        self.vectors_dir = os.path.join(base_dir, \"data\", \"vectors\")\n",
        "\n",
        "        # Components\n",
        "        self.tfidf_vectorizer = None\n",
        "        self.case_vectors_tfidf = None\n",
        "        self.case_ids = []\n",
        "\n",
        "        self.load_components()\n",
        "\n",
        "    def load_components(self) -> bool:\n",
        "        \"\"\"Load retrieval components\"\"\"\n",
        "        print(\"üîç Loading retrieval components...\")\n",
        "\n",
        "        # Find best vector file\n",
        "        vector_files = [f for f in os.listdir(self.vectors_dir) if f.endswith('.pkl')]\n",
        "\n",
        "        best_file = None\n",
        "        best_vocab_size = 0\n",
        "\n",
        "        for vf in vector_files:\n",
        "            if 'tfidf' in vf.lower():\n",
        "                try:\n",
        "                    with open(os.path.join(self.vectors_dir, vf), 'rb') as f:\n",
        "                        data = pickle.load(f)\n",
        "\n",
        "                    if 'vectorizer' in data:\n",
        "                        vocab_size = len(data['vectorizer'].get_feature_names_out())\n",
        "                        if vocab_size > best_vocab_size:\n",
        "                            best_vocab_size = vocab_size\n",
        "                            best_file = vf\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        if best_file:\n",
        "            file_path = os.path.join(self.vectors_dir, best_file)\n",
        "            with open(file_path, 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "\n",
        "            self.tfidf_vectorizer = data['vectorizer']\n",
        "            self.case_vectors_tfidf = data['vectors']\n",
        "            self.case_ids = data['case_ids']\n",
        "\n",
        "            if hasattr(self.case_vectors_tfidf, 'toarray'):\n",
        "                self.case_vectors_tfidf = self.case_vectors_tfidf.toarray()\n",
        "\n",
        "            print(f\"‚úÖ Loaded: {len(self.case_ids)} cases, {best_vocab_size:,} vocab\")\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def retrieve(self, query: str, k: int = 5) -> List[str]:\n",
        "        \"\"\"Retrieve top-k similar cases\"\"\"\n",
        "        if not self.tfidf_vectorizer or self.case_vectors_tfidf is None:\n",
        "            return []\n",
        "\n",
        "        # Preprocess query\n",
        "        processed_query = query.lower().strip()\n",
        "        processed_query = re.sub(r'\\s+', ' ', processed_query)\n",
        "\n",
        "        # Compute query vector\n",
        "        query_vector = self.tfidf_vectorizer.transform([processed_query])\n",
        "\n",
        "        if query_vector.nnz == 0:\n",
        "            return []\n",
        "\n",
        "        # Compute similarities\n",
        "        query_dense = query_vector.toarray() if hasattr(query_vector, 'toarray') else query_vector\n",
        "        similarities = cosine_similarity(query_dense, self.case_vectors_tfidf).flatten()\n",
        "\n",
        "        # Return top-k case_ids\n",
        "        top_indices = np.argsort(similarities)[::-1][:k]\n",
        "        return [self.case_ids[idx] for idx in top_indices]\n",
        "\n",
        "    def retrieve_with_scores(self, query: str, k: int = 5) -> List[Tuple[str, float]]:\n",
        "        \"\"\"Retrieve with similarity scores\"\"\"\n",
        "        if not self.tfidf_vectorizer or self.case_vectors_tfidf is None:\n",
        "            return []\n",
        "\n",
        "        processed_query = query.lower().strip()\n",
        "        query_vector = self.tfidf_vectorizer.transform([processed_query])\n",
        "\n",
        "        if query_vector.nnz == 0:\n",
        "            return []\n",
        "\n",
        "        query_dense = query_vector.toarray() if hasattr(query_vector, 'toarray') else query_vector\n",
        "        similarities = cosine_similarity(query_dense, self.case_vectors_tfidf).flatten()\n",
        "\n",
        "        top_indices = np.argsort(similarities)[::-1][:k]\n",
        "\n",
        "        results = []\n",
        "        for idx in top_indices:\n",
        "            case_id = self.case_ids[idx]\n",
        "            score = similarities[idx]\n",
        "            results.append((case_id, float(score)))\n",
        "\n",
        "        return results\n",
        "\n",
        "class SolutionExtractor:\n",
        "    \"\"\"\n",
        "    i. Ekstrak Solusi dari kasus top-k\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/terorisme\"):\n",
        "        self.base_dir = base_dir\n",
        "        self.raw_dir = os.path.join(base_dir, \"CLEANED\")\n",
        "        self.processed_dir = os.path.join(base_dir, \"data\", \"processed\")\n",
        "\n",
        "        # Storage untuk solusi\n",
        "        self.case_solutions = {}  # {case_id: solusi_text}\n",
        "        self.case_metadata = {}\n",
        "\n",
        "        print(\"üìÑ i. EKSTRAK SOLUSI\")\n",
        "\n",
        "    def load_case_metadata(self) -> bool:\n",
        "        \"\"\"Load metadata kasus dari cases.csv\"\"\"\n",
        "        cases_file = os.path.join(self.processed_dir, \"cases.csv\")\n",
        "\n",
        "        if not os.path.exists(cases_file):\n",
        "            print(\"‚ùå cases.csv not found\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(cases_file, encoding='utf-8')\n",
        "\n",
        "            for _, row in df.iterrows():\n",
        "                filename = row['nama_file']\n",
        "                case_id = filename.replace('.txt', '') if filename.endswith('.txt') else filename\n",
        "\n",
        "                self.case_metadata[case_id] = {\n",
        "                    'putusan': row.get('putusan', ''),\n",
        "                    'jenis_perkara': row.get('jenis_perkara', ''),\n",
        "                    'vonis': row.get('vonis', ''),\n",
        "                    'hukuman_pidana': row.get('hukuman_pidana', ''),\n",
        "                    'hukuman_denda': row.get('hukuman_denda', ''),\n",
        "                    'dakwaan': row.get('dakwaan', ''),\n",
        "                    'pasal_yang_dilanggar': row.get('pasal_yang_dilanggar', '')\n",
        "                }\n",
        "\n",
        "            print(f\"‚úÖ Loaded metadata for {len(self.case_metadata)} cases\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading metadata: {e}\")\n",
        "            return False\n",
        "\n",
        "    def extract_solution_from_text(self, text: str) -> str:\n",
        "        \"\"\"Ekstrak amar putusan atau ringkasan dari teks\"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        # Pattern untuk mencari amar putusan\n",
        "        putusan_patterns = [\n",
        "            r'(amar\\s+putusan[:\\s].*?)(?:\\n\\n|\\Z)',\n",
        "            r'(mengadili[:\\s].*?)(?:\\n\\n|\\Z)',\n",
        "            r'(memutuskan[:\\s].*?)(?:\\n\\n|\\Z)',\n",
        "            r'(menjatuhkan\\s+pidana[:\\s].*?)(?:\\n\\n|\\Z)',\n",
        "            r'(menghukum\\s+terdakwa[:\\s].*?)(?:\\n\\n|\\Z)'\n",
        "        ]\n",
        "\n",
        "        # Cari pattern putusan\n",
        "        for pattern in putusan_patterns:\n",
        "            matches = re.findall(pattern, text_lower, re.DOTALL | re.IGNORECASE)\n",
        "            if matches:\n",
        "                solution = matches[0].strip()\n",
        "                # Bersihkan dan ambil bagian penting\n",
        "                solution = re.sub(r'\\s+', ' ', solution)\n",
        "                solution = solution[:500]  # Batasi panjang\n",
        "                return solution\n",
        "\n",
        "        # Fallback: cari kalimat dengan kata kunci hukuman\n",
        "        hukuman_patterns = [\n",
        "            r'([^.]*(?:hukuman|pidana|denda|penjara|kurungan)[^.]*\\.)',\n",
        "            r'([^.]*(?:vonis|putusan|memutuskan)[^.]*\\.)',\n",
        "            r'([^.]*(?:terbukti|tidak terbukti)[^.]*\\.)'\n",
        "        ]\n",
        "\n",
        "        for pattern in hukuman_patterns:\n",
        "            matches = re.findall(pattern, text_lower)\n",
        "            if matches:\n",
        "                return matches[0].strip()[:300]\n",
        "\n",
        "        # Fallback terakhir: ambil bagian tengah dokumen\n",
        "        lines = text.split('\\n')\n",
        "        middle_start = len(lines) // 3\n",
        "        middle_end = 2 * len(lines) // 3\n",
        "        middle_text = ' '.join(lines[middle_start:middle_end])\n",
        "\n",
        "        return middle_text[:200].strip()\n",
        "\n",
        "    def create_solution_from_metadata(self, case_id: str) -> str:\n",
        "        \"\"\"Buat solusi dari metadata yang tersedia\"\"\"\n",
        "        if case_id not in self.case_metadata:\n",
        "            return \"Solusi tidak tersedia\"\n",
        "\n",
        "        meta = self.case_metadata[case_id]\n",
        "        solution_parts = []\n",
        "\n",
        "        # Jenis perkara\n",
        "        if meta['jenis_perkara']:\n",
        "            solution_parts.append(f\"Jenis: {meta['jenis_perkara']}\")\n",
        "\n",
        "        # Putusan\n",
        "        if meta['putusan']:\n",
        "            solution_parts.append(f\"Putusan: {meta['putusan']}\")\n",
        "\n",
        "        # Vonis\n",
        "        if meta['vonis']:\n",
        "            solution_parts.append(f\"Vonis: {meta['vonis']}\")\n",
        "\n",
        "        # Hukuman\n",
        "        if meta['hukuman_pidana']:\n",
        "            solution_parts.append(f\"Hukuman: {meta['hukuman_pidana']}\")\n",
        "\n",
        "        if meta['hukuman_denda']:\n",
        "            solution_parts.append(f\"Denda: {meta['hukuman_denda']}\")\n",
        "\n",
        "        # Pasal\n",
        "        if meta['pasal_yang_dilanggar']:\n",
        "            solution_parts.append(f\"Pasal: {meta['pasal_yang_dilanggar']}\")\n",
        "\n",
        "        if solution_parts:\n",
        "            return \"; \".join(solution_parts)\n",
        "        else:\n",
        "            return \"Informasi putusan tidak lengkap\"\n",
        "\n",
        "    def extract_all_solutions(self, case_ids: List[str]) -> Dict[str, str]:\n",
        "        \"\"\"\n",
        "        1. Dari kasus top-k, ambil amar putusan atau ringkasan dakwaan\n",
        "        2. Simpan di struktur: {case_id: solusi_text}\n",
        "        \"\"\"\n",
        "        print(f\"\\nüìÑ Extracting solutions for {len(case_ids)} cases...\")\n",
        "\n",
        "        # Load metadata\n",
        "        self.load_case_metadata()\n",
        "\n",
        "        solutions = {}\n",
        "\n",
        "        for case_id in case_ids:\n",
        "            try:\n",
        "                # Strategy 1: Extract from raw text\n",
        "                raw_file = os.path.join(self.raw_dir, f\"{case_id}.txt\")\n",
        "\n",
        "                if os.path.exists(raw_file):\n",
        "                    with open(raw_file, 'r', encoding='utf-8') as f:\n",
        "                        text = f.read()\n",
        "\n",
        "                    solution = self.extract_solution_from_text(text)\n",
        "\n",
        "                    if len(solution.strip()) > 20:  # Valid solution\n",
        "                        solutions[case_id] = solution\n",
        "                        continue\n",
        "\n",
        "                # Strategy 2: Use metadata\n",
        "                solution = self.create_solution_from_metadata(case_id)\n",
        "                solutions[case_id] = solution\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error extracting solution for {case_id}: {e}\")\n",
        "                solutions[case_id] = \"Solusi tidak dapat diekstrak\"\n",
        "\n",
        "        print(f\"‚úÖ Extracted {len(solutions)} solutions\")\n",
        "\n",
        "        # Show sample solutions\n",
        "        sample_cases = list(solutions.keys())[:3]\n",
        "        for case_id in sample_cases:\n",
        "            solution = solutions[case_id]\n",
        "            short_solution = solution[:100] + \"...\" if len(solution) > 100 else solution\n",
        "            print(f\"   {case_id}: {short_solution}\")\n",
        "\n",
        "        self.case_solutions = solutions\n",
        "        return solutions\n"
      ],
      "metadata": {
        "id": "0HXBmk54HX8-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Algoritma Prediksi dan Implementasi Fungsi**"
      ],
      "metadata": {
        "id": "0mA6QqzRH0pJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ii. ALGORITMA PREDIKSI\n",
        "# 1. Majority vote: pilih solusi yang paling banyak muncul\n",
        "# 2. Weighted similarity: bobot = skor similarity\n",
        "# ============================================================================\n",
        "\n",
        "class SolutionPredictor:\n",
        "    \"\"\"\n",
        "    ii. Algoritma Prediksi & iii. Implementasi Fungsi\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/terorisme\"):\n",
        "        self.base_dir = base_dir\n",
        "\n",
        "        # Components\n",
        "        self.retrieval_system = RetrievalSystem(base_dir)\n",
        "        self.solution_extractor = SolutionExtractor(base_dir)\n",
        "\n",
        "        # Cache all solutions untuk efisiensi\n",
        "        self._initialize_solution_cache()\n",
        "\n",
        "        print(\"üîÆ ii. ALGORITMA PREDIKSI\")\n",
        "\n",
        "    def _initialize_solution_cache(self):\n",
        "        \"\"\"Initialize cache dengan semua solusi yang tersedia\"\"\"\n",
        "        print(\"üíæ Initializing solution cache...\")\n",
        "\n",
        "        if self.retrieval_system.case_ids:\n",
        "            # Extract solutions untuk semua cases\n",
        "            all_solutions = self.solution_extractor.extract_all_solutions(\n",
        "                self.retrieval_system.case_ids\n",
        "            )\n",
        "            print(f\"‚úÖ Cached {len(all_solutions)} solutions\")\n",
        "\n",
        "    def majority_vote(self, solutions: List[str]) -> str:\n",
        "        \"\"\"\n",
        "        1. Majority vote: pilih solusi yang paling banyak muncul\n",
        "        \"\"\"\n",
        "        if not solutions:\n",
        "            return \"Tidak ada solusi tersedia\"\n",
        "\n",
        "        # Normalisasi solusi untuk counting\n",
        "        normalized_solutions = []\n",
        "        for sol in solutions:\n",
        "            # Ambil kata kunci utama\n",
        "            sol_lower = sol.lower()\n",
        "\n",
        "            # Extract key decision words\n",
        "            key_words = []\n",
        "            if 'terbukti' in sol_lower and 'tidak' not in sol_lower:\n",
        "                key_words.append('terbukti')\n",
        "            elif 'tidak terbukti' in sol_lower:\n",
        "                key_words.append('tidak_terbukti')\n",
        "\n",
        "            if 'penjara' in sol_lower or 'pidana' in sol_lower:\n",
        "                key_words.append('penjara')\n",
        "            if 'denda' in sol_lower:\n",
        "                key_words.append('denda')\n",
        "            if 'bebas' in sol_lower:\n",
        "                key_words.append('bebas')\n",
        "\n",
        "            normalized = '_'.join(key_words) if key_words else 'unknown'\n",
        "            normalized_solutions.append(normalized)\n",
        "\n",
        "        # Count occurrences\n",
        "        counter = Counter(normalized_solutions)\n",
        "        most_common = counter.most_common(1)[0][0]\n",
        "\n",
        "        # Map back to original solution\n",
        "        for i, norm_sol in enumerate(normalized_solutions):\n",
        "            if norm_sol == most_common:\n",
        "                return solutions[i]\n",
        "\n",
        "        return solutions[0]  # Fallback\n",
        "\n",
        "    def weighted_similarity(self, solutions: List[str], scores: List[float]) -> str:\n",
        "        \"\"\"\n",
        "        2. Weighted similarity: bobot = skor similarity\n",
        "        \"\"\"\n",
        "        if not solutions or not scores:\n",
        "            return \"Tidak ada solusi tersedia\"\n",
        "\n",
        "        # Normalisasi scores\n",
        "        total_score = sum(scores)\n",
        "        if total_score == 0:\n",
        "            return self.majority_vote(solutions)\n",
        "\n",
        "        weights = [score / total_score for score in scores]\n",
        "\n",
        "        # Group solutions by similarity\n",
        "        solution_weights = defaultdict(float)\n",
        "        solution_examples = {}\n",
        "\n",
        "        for sol, weight in zip(solutions, weights):\n",
        "            # Simplify solution for grouping\n",
        "            sol_key = self._simplify_solution(sol)\n",
        "            solution_weights[sol_key] += weight\n",
        "            if sol_key not in solution_examples:\n",
        "                solution_examples[sol_key] = sol\n",
        "\n",
        "        # Pilih solusi dengan weight tertinggi\n",
        "        best_solution_key = max(solution_weights, key=solution_weights.get)\n",
        "        return solution_examples[best_solution_key]\n",
        "\n",
        "    def _simplify_solution(self, solution: str) -> str:\n",
        "        \"\"\"Simplify solution untuk grouping\"\"\"\n",
        "        sol_lower = solution.lower()\n",
        "\n",
        "        if 'tidak terbukti' in sol_lower or 'bebas' in sol_lower:\n",
        "            return 'tidak_terbukti'\n",
        "        elif 'terbukti' in sol_lower:\n",
        "            if 'penjara' in sol_lower and 'denda' in sol_lower:\n",
        "                return 'terbukti_penjara_denda'\n",
        "            elif 'penjara' in sol_lower:\n",
        "                return 'terbukti_penjara'\n",
        "            elif 'denda' in sol_lower:\n",
        "                return 'terbukti_denda'\n",
        "            else:\n",
        "                return 'terbukti'\n",
        "        else:\n",
        "                return 'unknown'\n",
        "\n",
        "    def predict_outcome(self, query: str, k: int = 5, method: str = 'weighted') -> Dict:\n",
        "        \"\"\"\n",
        "        Implementasi Fungsi predict_outcome sesuai spesifikasi\n",
        "        \"\"\"\n",
        "        # Retrieve top-k similar cases\n",
        "        if method == 'weighted':\n",
        "            top_cases_with_scores = self.retrieval_system.retrieve_with_scores(query, k=k)\n",
        "            top_k = [case for case, score in top_cases_with_scores]\n",
        "            scores = [score for case, score in top_cases_with_scores]\n",
        "        else:\n",
        "            top_k = self.retrieval_system.retrieve(query, k=k)\n",
        "            scores = [1.0] * len(top_k)  # Equal weights for majority vote\n",
        "\n",
        "        if not top_k:\n",
        "            return {\n",
        "                'predicted_solution': \"Tidak dapat menemukan kasus serupa\",\n",
        "                'top_cases': [],\n",
        "                'method': method,\n",
        "                'confidence': 0.0\n",
        "            }\n",
        "\n",
        "        # Extract solutions from top-k cases\n",
        "        solutions = []\n",
        "        valid_cases = []\n",
        "        valid_scores = []\n",
        "\n",
        "        for i, case_id in enumerate(top_k):\n",
        "            if case_id in self.solution_extractor.case_solutions:\n",
        "                solution = self.solution_extractor.case_solutions[case_id]\n",
        "                solutions.append(solution)\n",
        "                valid_cases.append(case_id)\n",
        "                valid_scores.append(scores[i])\n",
        "\n",
        "        if not solutions:\n",
        "            return {\n",
        "                'predicted_solution': \"Solusi tidak tersedia untuk kasus serupa\",\n",
        "                'top_cases': top_k,\n",
        "                'method': method,\n",
        "                'confidence': 0.0\n",
        "            }\n",
        "\n",
        "        # Apply prediction algorithm\n",
        "        if method == 'majority':\n",
        "            predicted_solution = self.majority_vote(solutions)\n",
        "        else:  # weighted\n",
        "            predicted_solution = self.weighted_similarity(solutions, valid_scores)\n",
        "\n",
        "        # Calculate confidence\n",
        "        confidence = sum(valid_scores) / len(valid_scores) if valid_scores else 0.0\n",
        "\n",
        "        return {\n",
        "            'predicted_solution': predicted_solution,\n",
        "            'top_cases': valid_cases,\n",
        "            'case_solutions': dict(zip(valid_cases, solutions)),\n",
        "            'similarity_scores': valid_scores,\n",
        "            'method': method,\n",
        "            'confidence': confidence,\n",
        "            'query': query\n",
        "        }"
      ],
      "metadata": {
        "id": "xC6tTUuQH6fh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Demo Manual**"
      ],
      "metadata": {
        "id": "YamiO_LMIAaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# iv. DEMO MANUAL\n",
        "# 1. Siapkan 5 contoh kasus baru ‚Üí jalankan predict_outcome() ‚Üí\n",
        "#    bandingkan dengan putusan sebenarnya\n",
        "# ============================================================================\n",
        "\n",
        "class ManualDemo:\n",
        "    \"\"\"\n",
        "    iv. Demo Manual\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/terorisme\"):\n",
        "        self.base_dir = base_dir\n",
        "        self.results_dir = os.path.join(base_dir, \"data\", \"results\")\n",
        "\n",
        "        os.makedirs(self.results_dir, exist_ok=True)\n",
        "\n",
        "        self.predictor = SolutionPredictor(base_dir)\n",
        "\n",
        "        print(\"üß™ iv. DEMO MANUAL\")\n",
        "\n",
        "    def create_demo_cases(self) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        1. Siapkan 5 contoh kasus baru\n",
        "        \"\"\"\n",
        "        demo_cases = [\n",
        "             {\n",
        "        \"query_id\": \"DEMO_001\",\n",
        "        \"query\": \"aksi terorisme dengan peledakan bom di terminal bus kota\",\n",
        "        \"expected_outcome\": \"Terbukti bersalah, pidana penjara seumur hidup\",\n",
        "        \"description\": \"Peledakan bom di fasilitas umum\"\n",
        "    },\n",
        "    {\n",
        "        \"query_id\": \"DEMO_002\",\n",
        "        \"query\": \"penangkapan anggota kelompok teroris yang merencanakan serangan terhadap aparat\",\n",
        "        \"expected_outcome\": \"Terbukti bersalah, pidana penjara\",\n",
        "        \"description\": \"Perencanaan serangan terhadap aparat\"\n",
        "    },\n",
        "    {\n",
        "        \"query_id\": \"DEMO_003\",\n",
        "        \"query\": \"radikalisasi mahasiswa melalui media sosial oleh jaringan teror\",\n",
        "        \"expected_outcome\": \"Terbukti bersalah, pidana penjara dan rehabilitasi\",\n",
        "        \"description\": \"Radikalisasi generasi muda\"\n",
        "    },\n",
        "    {\n",
        "        \"query_id\": \"DEMO_004\",\n",
        "        \"query\": \"pengiriman dana dari luar negeri untuk mendanai aksi teror di indonesia\",\n",
        "        \"expected_outcome\": \"Terbukti bersalah, pidana penjara dan perampasan dana\",\n",
        "        \"description\": \"Pendanaan terorisme lintas negara\"\n",
        "    },\n",
        "    {\n",
        "        \"query_id\": \"DEMO_005\",\n",
        "        \"query\": \"penggerebekan tempat persembunyian kelompok teroris oleh densus 88\",\n",
        "        \"expected_outcome\": \"Penangkapan berhasil, proses hukum berjalan\",\n",
        "        \"description\": \"Penggerebekan dan penangkapan\"\n",
        "    }\n",
        "        ]\n",
        "\n",
        "        print(f\"üìù Created {len(demo_cases)} demo cases\")\n",
        "        for case in demo_cases:\n",
        "            print(f\"   {case['query_id']}: {case['description']}\")\n",
        "\n",
        "        return demo_cases\n",
        "\n",
        "    def run_demo(self) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        2. Jalankan predict_outcome() untuk setiap kasus demo\n",
        "        \"\"\"\n",
        "        demo_cases = self.create_demo_cases()\n",
        "        results = []\n",
        "\n",
        "        print(f\"\\nüîÆ Running prediction demo...\")\n",
        "\n",
        "        for case in demo_cases:\n",
        "            query_id = case['query_id']\n",
        "            query = case['query']\n",
        "            expected = case['expected_outcome']\n",
        "\n",
        "            print(f\"\\n--- {query_id} ---\")\n",
        "            print(f\"Query: {query}\")\n",
        "            print(f\"Expected: {expected}\")\n",
        "\n",
        "            # Test both methods\n",
        "            for method in ['weighted', 'majority']:\n",
        "                try:\n",
        "                    prediction_result = self.predictor.predict_outcome(\n",
        "                        query=query,\n",
        "                        k=5,\n",
        "                        method=method\n",
        "                    )\n",
        "\n",
        "                    predicted_solution = prediction_result['predicted_solution']\n",
        "                    confidence = prediction_result['confidence']\n",
        "                    top_cases = prediction_result['top_cases']\n",
        "\n",
        "                    print(f\"\\n{method.upper()} Method:\")\n",
        "                    print(f\"  Predicted: {predicted_solution[:100]}...\")\n",
        "                    print(f\"  Confidence: {confidence:.3f}\")\n",
        "                    print(f\"  Top cases: {top_cases[:3]}\")\n",
        "\n",
        "                    # Compare with expected\n",
        "                    comparison = self.compare_prediction(predicted_solution, expected)\n",
        "                    print(f\"  Match score: {comparison['score']:.2f}\")\n",
        "\n",
        "                    result = {\n",
        "                        'query_id': query_id,\n",
        "                        'query': query,\n",
        "                        'method': method,\n",
        "                        'predicted_solution': predicted_solution,\n",
        "                        'expected_outcome': expected,\n",
        "                        'confidence': confidence,\n",
        "                        'top_cases': top_cases,\n",
        "                        'match_score': comparison['score'],\n",
        "                        'match_explanation': comparison['explanation']\n",
        "                    }\n",
        "\n",
        "                    results.append(result)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  ‚ùå Error: {e}\")\n",
        "\n",
        "                    error_result = {\n",
        "                        'query_id': query_id,\n",
        "                        'query': query,\n",
        "                        'method': method,\n",
        "                        'predicted_solution': f\"Error: {str(e)}\",\n",
        "                        'expected_outcome': expected,\n",
        "                        'confidence': 0.0,\n",
        "                        'top_cases': [],\n",
        "                        'match_score': 0.0,\n",
        "                        'match_explanation': 'Prediction failed'\n",
        "                    }\n",
        "\n",
        "                    results.append(error_result)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def compare_prediction(self, predicted: str, expected: str) -> Dict:\n",
        "        \"\"\"\n",
        "        3. Bandingkan dengan putusan sebenarnya\n",
        "        \"\"\"\n",
        "        pred_lower = predicted.lower()\n",
        "        exp_lower = expected.lower()\n",
        "\n",
        "        score = 0.0\n",
        "        explanations = []\n",
        "\n",
        "        # Check for key terms\n",
        "        key_terms = [\n",
        "            ('terbukti', 0.3),\n",
        "            ('tidak terbukti', 0.3),\n",
        "            ('penjara', 0.2),\n",
        "            ('pidana', 0.2),\n",
        "            ('denda', 0.15),\n",
        "            ('bebas', 0.2)\n",
        "        ]\n",
        "\n",
        "        for term, weight in key_terms:\n",
        "            if term in pred_lower and term in exp_lower:\n",
        "                score += weight\n",
        "                explanations.append(f\"‚úÖ Found '{term}'\")\n",
        "            elif term in exp_lower and term not in pred_lower:\n",
        "                explanations.append(f\"‚ùå Missing '{term}'\")\n",
        "            elif term in pred_lower and term not in exp_lower:\n",
        "                explanations.append(f\"‚ö†Ô∏è Extra '{term}'\")\n",
        "\n",
        "        # Bonus for overall direction match\n",
        "        if ('terbukti' in pred_lower and 'terbukti' in exp_lower) or \\\n",
        "           ('tidak terbukti' in pred_lower and ('tidak terbukti' in exp_lower or 'bebas' in exp_lower)):\n",
        "            score += 0.2\n",
        "            explanations.append(\"‚úÖ Overall direction matches\")\n",
        "\n",
        "        score = min(score, 1.0)  # Cap at 1.0\n",
        "\n",
        "        return {\n",
        "            'score': score,\n",
        "            'explanation': '; '.join(explanations)\n",
        "        }"
      ],
      "metadata": {
        "id": "Tj0VjusfIGeE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# v. OUTPUT\n",
        "# 1. Script 04_predict.py / notebook\n",
        "# 2. File /data/results/predictions.csv berisi:\n",
        "#    query_id predicted_solution top_5_case_ids\n",
        "# ============================================================================\n",
        "\n",
        "class OutputGenerator:\n",
        "    \"\"\"\n",
        "    v. Output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/terorisme\"):\n",
        "        self.base_dir = base_dir\n",
        "        self.results_dir = os.path.join(base_dir, \"data\", \"results\")\n",
        "\n",
        "        os.makedirs(self.results_dir, exist_ok=True)\n",
        "\n",
        "        print(\"üìä v. OUTPUT\")\n",
        "\n",
        "    def save_predictions_csv(self, results: List[Dict]) -> str:\n",
        "        \"\"\"\n",
        "        2. File /data/results/predictions.csv berisi:\n",
        "           query_id predicted_solution top_5_case_ids\n",
        "        \"\"\"\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        csv_filename = f\"predictions_{timestamp}.csv\"\n",
        "        csv_path = os.path.join(self.results_dir, csv_filename)\n",
        "\n",
        "        # Prepare data for CSV\n",
        "        csv_data = []\n",
        "\n",
        "        for result in results:\n",
        "            # Convert top_cases list to string\n",
        "            top_5_case_ids = ';'.join(result['top_cases'][:5])\n",
        "\n",
        "            csv_row = {\n",
        "                'query_id': result['query_id'],\n",
        "                'query': result['query'],\n",
        "                'method': result['method'],\n",
        "                'predicted_solution': result['predicted_solution'],\n",
        "                'expected_outcome': result['expected_outcome'],\n",
        "                'top_5_case_ids': top_5_case_ids,\n",
        "                'confidence': result['confidence'],\n",
        "                'match_score': result['match_score'],\n",
        "                'match_explanation': result['match_explanation']\n",
        "            }\n",
        "\n",
        "            csv_data.append(csv_row)\n",
        "\n",
        "        # Save to CSV\n",
        "        df = pd.DataFrame(csv_data)\n",
        "        df.to_csv(csv_path, index=False, encoding='utf-8')\n",
        "\n",
        "        print(f\"üìÑ Predictions saved: {csv_filename}\")\n",
        "        print(f\"   Records: {len(csv_data)}\")\n",
        "        print(f\"   Columns: {list(df.columns)}\")\n",
        "\n",
        "        return csv_path\n",
        "\n",
        "    def save_detailed_results(self, results: List[Dict]) -> str:\n",
        "        \"\"\"Save detailed results as JSON\"\"\"\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        json_filename = f\"detailed_predictions_{timestamp}.json\"\n",
        "        json_path = os.path.join(self.results_dir, json_filename)\n",
        "\n",
        "        detailed_data = {\n",
        "            'metadata': {\n",
        "                'generated_at': datetime.now().isoformat(),\n",
        "                'total_predictions': len(results),\n",
        "                'methods_used': list(set([r['method'] for r in results])),\n",
        "                'version': 'solution_reuse_v1'\n",
        "            },\n",
        "            'results': results\n",
        "        }\n",
        "\n",
        "        with open(json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(detailed_data, f, ensure_ascii=False, indent=2, default=str)\n",
        "\n",
        "        print(f\"üìÑ Detailed results saved: {json_filename}\")\n",
        "\n",
        "        return json_path\n",
        "\n",
        "    def generate_summary_report(self, results: List[Dict]) -> str:\n",
        "        \"\"\"Generate summary report\"\"\"\n",
        "        report = []\n",
        "        report.append(\"=\" * 70)\n",
        "        report.append(\"üîÆ TAHAP 4 - SOLUTION REUSE - SUMMARY REPORT\")\n",
        "        report.append(\"=\" * 70)\n",
        "        report.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Overall statistics\n",
        "        total_predictions = len(results)\n",
        "        successful_predictions = len([r for r in results if 'Error' not in r['predicted_solution']])\n",
        "        avg_confidence = np.mean([r['confidence'] for r in results if r['confidence'] > 0])\n",
        "        avg_match_score = np.mean([r['match_score'] for r in results])\n",
        "\n",
        "        report.append(\"üìä OVERALL STATISTICS:\")\n",
        "        report.append(f\"  Total predictions: {total_predictions}\")\n",
        "        report.append(f\"  Successful predictions: {successful_predictions} ({successful_predictions/total_predictions*100:.1f}%)\")\n",
        "        report.append(f\"  Average confidence: {avg_confidence:.3f}\")\n",
        "        report.append(f\"  Average match score: {avg_match_score:.3f}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Method comparison\n",
        "        methods = list(set([r['method'] for r in results]))\n",
        "        report.append(\"üîß METHOD COMPARISON:\")\n",
        "\n",
        "        for method in methods:\n",
        "            method_results = [r for r in results if r['method'] == method]\n",
        "            method_confidence = np.mean([r['confidence'] for r in method_results if r['confidence'] > 0])\n",
        "            method_match = np.mean([r['match_score'] for r in method_results])\n",
        "\n",
        "            report.append(f\"  {method.upper()}:\")\n",
        "            report.append(f\"    Avg Confidence: {method_confidence:.3f}\")\n",
        "            report.append(f\"    Avg Match Score: {method_match:.3f}\")\n",
        "\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Best predictions\n",
        "        report.append(\"üèÜ BEST PREDICTIONS:\")\n",
        "        best_results = sorted([r for r in results if r['match_score'] > 0],\n",
        "                             key=lambda x: x['match_score'], reverse=True)[:3]\n",
        "\n",
        "        for i, result in enumerate(best_results, 1):\n",
        "            report.append(f\"  {i}. {result['query_id']} ({result['method']})\")\n",
        "            report.append(f\"     Query: {result['query'][:50]}...\")\n",
        "            report.append(f\"     Match Score: {result['match_score']:.3f}\")\n",
        "            report.append(f\"     Confidence: {result['confidence']:.3f}\")\n",
        "\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Performance assessment\n",
        "        if avg_match_score >= 0.7:\n",
        "            report.append(\"üéâ EXCELLENT: System performing very well!\")\n",
        "        elif avg_match_score >= 0.5:\n",
        "            report.append(\"‚úÖ GOOD: System performing adequately\")\n",
        "        elif avg_match_score >= 0.3:\n",
        "            report.append(\"‚ö†Ô∏è FAIR: System needs improvement\")\n",
        "        else:\n",
        "            report.append(\"‚ùå POOR: System requires significant work\")\n",
        "\n",
        "        report.append(\"=\" * 70)\n",
        "\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "class SolutionReuseSystem:\n",
        "    \"\"\"\n",
        "    Main class untuk Tahap 4 - Solution Reuse\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_dir=\"/content/drive/MyDrive/terorisme\"):\n",
        "        self.base_dir = base_dir\n",
        "\n",
        "        print(\"üîÆ TAHAP 4 - SOLUTION REUSE\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"Tujuan: Gunakan putusan lama sebagai dasar pencarian untuk kasus baru\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Initialize components\n",
        "        self.solution_extractor = SolutionExtractor(base_dir)\n",
        "        self.predictor = SolutionPredictor(base_dir)\n",
        "        self.demo = ManualDemo(base_dir)\n",
        "        self.output_generator = OutputGenerator(base_dir)\n",
        "\n",
        "    def run_complete_solution_reuse(self) -> bool:\n",
        "        \"\"\"\n",
        "        Jalankan semua tahap solution reuse\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(\"\\nüîÆ Running complete solution reuse process...\")\n",
        "\n",
        "            # iv. Demo Manual\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"üß™ iv. DEMO MANUAL\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            demo_results = self.demo.run_demo()\n",
        "\n",
        "            if not demo_results:\n",
        "                print(\"‚ùå Demo failed - no results generated\")\n",
        "                return False\n",
        "\n",
        "            # v. Output\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(\"üìä v. OUTPUT\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            # Save CSV\n",
        "            csv_path = self.output_generator.save_predictions_csv(demo_results)\n",
        "\n",
        "            # Save detailed JSON\n",
        "            json_path = self.output_generator.save_detailed_results(demo_results)\n",
        "\n",
        "            # Generate and show report\n",
        "            report = self.output_generator.generate_summary_report(demo_results)\n",
        "            print(f\"\\n{report}\")\n",
        "\n",
        "            # Final success message\n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(\"‚úÖ TAHAP 4 - SOLUTION REUSE COMPLETED!\")\n",
        "            print(\"üìÅ Output files created:\")\n",
        "            print(f\"   - {os.path.basename(csv_path)}\")\n",
        "            print(f\"   - {os.path.basename(json_path)}\")\n",
        "            print(\"üîÆ Solution reuse system ready for production!\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error in solution reuse process: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return False\n",
        "\n",
        "def test_individual_components():\n",
        "    \"\"\"Test individual components untuk debugging\"\"\"\n",
        "    print(\"üß™ TESTING INDIVIDUAL COMPONENTS\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    base_dir = \"/content/drive/MyDrive/terorisme\"\n",
        "\n",
        "    # Test 1: Retrieval System\n",
        "    print(\"\\n1. Testing Retrieval System...\")\n",
        "    try:\n",
        "        retrieval = RetrievalSystem(base_dir)\n",
        "        if retrieval.case_ids:\n",
        "            test_query = \"penangkapan anggota kelompok teroris\"\n",
        "            results = retrieval.retrieve(test_query, k=3)\n",
        "            print(f\"‚úÖ Retrieval working: {len(results)} results for '{test_query}'\")\n",
        "        else:\n",
        "            print(\"‚ùå Retrieval system has no cases\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Retrieval test failed: {e}\")\n",
        "\n",
        "    # Test 2: Solution Extractor\n",
        "    print(\"\\n2. Testing Solution Extractor...\")\n",
        "    try:\n",
        "        extractor = SolutionExtractor(base_dir)\n",
        "        if extractor.load_case_metadata():\n",
        "            sample_cases = list(extractor.case_metadata.keys())[:3]\n",
        "            solutions = extractor.extract_all_solutions(sample_cases)\n",
        "            print(f\"‚úÖ Extraction working: {len(solutions)} solutions extracted\")\n",
        "        else:\n",
        "            print(\"‚ùå Cannot load case metadata\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Extraction test failed: {e}\")\n",
        "\n",
        "    # Test 3: Predictor\n",
        "    print(\"\\n3. Testing Predictor...\")\n",
        "    try:\n",
        "        predictor = SolutionPredictor(base_dir)\n",
        "        test_query = \"penyuapan pejabat\"\n",
        "        result = predictor.predict_outcome(test_query, k=3)\n",
        "        print(f\"‚úÖ Prediction working: '{result['predicted_solution'][:50]}...'\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Prediction test failed: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fungsi utama untuk Tahap 4 - Solution Reuse\n",
        "    \"\"\"\n",
        "    print(\"üöÄ MULAI TAHAP 4 - SOLUTION REUSE\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    try:\n",
        "        # Optional: Test individual components first\n",
        "        # test_individual_components()\n",
        "\n",
        "        # Run complete solution reuse system\n",
        "        system = SolutionReuseSystem()\n",
        "        success = system.run_complete_solution_reuse()\n",
        "\n",
        "        if success:\n",
        "            print(f\"\\nüéâ TAHAP 4 BERHASIL!\")\n",
        "            print(\"‚ú® Yang telah diselesaikan:\")\n",
        "            print(\"  ‚úÖ i. Ekstrak Solusi dari kasus top-k\")\n",
        "            print(\"  ‚úÖ ii. Algoritma Prediksi (majority vote & weighted similarity)\")\n",
        "            print(\"  ‚úÖ iii. Implementasi Fungsi predict_outcome()\")\n",
        "            print(\"  ‚úÖ iv. Demo Manual dengan 5 contoh kasus\")\n",
        "            print(\"  ‚úÖ v. Output CSV dan JSON hasil prediksi\")\n",
        "            print(\"üîÆ Solution reuse system siap digunakan!\")\n",
        "        else:\n",
        "            print(\"\\n‚ùå Tahap 4 gagal diselesaikan\")\n",
        "            print(\"üîß Jalankan test_individual_components() untuk debugging\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nüí• ERROR: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# ============================================================================\n",
        "# ADDITIONAL UTILITY FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def quick_predict(query: str, base_dir=\"/content/drive/MyDrive/terorisme\") -> str:\n",
        "    \"\"\"\n",
        "    Quick prediction function untuk testing cepat\n",
        "\n",
        "    Usage:\n",
        "    result = quick_predict(\"penangkapan anggota kelompok teroris\")\n",
        "    print(result)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        predictor = SolutionPredictor(base_dir)\n",
        "        result = predictor.predict_outcome(query, k=5, method='weighted')\n",
        "        return result['predicted_solution']\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def batch_predict(queries: List[str], base_dir=\"/content/drive/MyDrive/terorisme\") -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Batch prediction untuk multiple queries\n",
        "\n",
        "    Usage:\n",
        "    queries = [ \"aksi terorisme di tempat umum\",\n",
        "    \"penangkapan anggota kelompok teroris\",\n",
        "    \"pendanaan jaringan terorisme dari luar negeri\"]\n",
        "    results = batch_predict(queries)\n",
        "    \"\"\"\n",
        "    predictor = SolutionPredictor(base_dir)\n",
        "    results = []\n",
        "\n",
        "    for i, query in enumerate(queries):\n",
        "        try:\n",
        "            result = predictor.predict_outcome(query, k=5, method='weighted')\n",
        "            result['query_id'] = f\"BATCH_{i+1:03d}\"\n",
        "            results.append(result)\n",
        "        except Exception as e:\n",
        "            error_result = {\n",
        "                'query_id': f\"BATCH_{i+1:03d}\",\n",
        "                'query': query,\n",
        "                'predicted_solution': f\"Error: {str(e)}\",\n",
        "                'confidence': 0.0,\n",
        "                'top_cases': []\n",
        "            }\n",
        "            results.append(error_result)\n",
        "\n",
        "    return results\n",
        "\n",
        "def interactive_demo(base_dir=\"/content/drive/MyDrive/terorisme\"):\n",
        "    \"\"\"\n",
        "    Interactive demo untuk testing manual\n",
        "    \"\"\"\n",
        "    print(\"üîÆ INTERACTIVE SOLUTION REUSE DEMO\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"Masukkan query kasus hukum (atau 'quit' untuk keluar)\")\n",
        "\n",
        "    predictor = SolutionPredictor(base_dir)\n",
        "\n",
        "    while True:\n",
        "        query = input(\"\\nüîç Query: \").strip()\n",
        "\n",
        "        if query.lower() in ['quit', 'exit', 'q']:\n",
        "            break\n",
        "\n",
        "        if not query:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            print(f\"üîÆ Predicting for: '{query}'\")\n",
        "\n",
        "            # Test both methods\n",
        "            for method in ['weighted', 'majority']:\n",
        "                result = predictor.predict_outcome(query, k=5, method=method)\n",
        "\n",
        "                print(f\"\\n{method.upper()} METHOD:\")\n",
        "                print(f\"Prediction: {result['predicted_solution']}\")\n",
        "                print(f\"Confidence: {result['confidence']:.3f}\")\n",
        "                print(f\"Top cases: {result['top_cases'][:3]}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {e}\")\n",
        "\n",
        "    print(\"üëã Demo selesai!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lfk5qx7IdHB",
        "outputId": "cce1c5a1-f7c1-4014-fb3e-70b8a9ffb922"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ MULAI TAHAP 4 - SOLUTION REUSE\n",
            "======================================================================\n",
            "üîÆ TAHAP 4 - SOLUTION REUSE\n",
            "============================================================\n",
            "Tujuan: Gunakan putusan lama sebagai dasar pencarian untuk kasus baru\n",
            "============================================================\n",
            "üìÑ i. EKSTRAK SOLUSI\n",
            "üîç Loading retrieval components...\n",
            "‚úÖ Loaded: 46 cases, 3,440 vocab\n",
            "üìÑ i. EKSTRAK SOLUSI\n",
            "üíæ Initializing solution cache...\n",
            "\n",
            "üìÑ Extracting solutions for 46 cases...\n",
            "‚úÖ Loaded metadata for 46 cases\n",
            "‚úÖ Extracted 46 solutions\n",
            "   case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_631_Pid_Sus_2023_PN_JKT_TIM_Tanggal_14_Desember_2023__Penuntut_Umum_ANDI_JEFRI_ARDIN__S_H_Terdakwa_DIAN_YUDI_SAPUTRA_alias_ABU_HANIF_Bin_WAHYU_ILAHI__Alm: mengadili perkara pidana denganacara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan seb...\n",
            "   case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_629_Pid_Sus_2023_PN_JKT_TIM_Tanggal_14_Desember_2023__Penuntut_Umum_HERRY_WIYANTO__SH__M_HumTerdakwa_TAJUDIN_Als_PAK_HAJI_TAJUDIN_Als_PAK_TEJE_Als_PAKWA_URA: mengadili perkara pidana denganacara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan seb...\n",
            "   case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_555_Pid_Sus_2023_PN_JKT_TIM_Tanggal_13_Desember_2023__Penuntut_Umum_ERWIN_INDRAPUTRA__SH___MHTerdakwa_ARIS_BUDIANTO_alias_RIKO_alias_BAHAR_alias_SARAHARSONO: mengadili perkara pidana denganacara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan seb...\n",
            "‚úÖ Cached 46 solutions\n",
            "üîÆ ii. ALGORITMA PREDIKSI\n",
            "üîç Loading retrieval components...\n",
            "‚úÖ Loaded: 46 cases, 3,440 vocab\n",
            "üìÑ i. EKSTRAK SOLUSI\n",
            "üíæ Initializing solution cache...\n",
            "\n",
            "üìÑ Extracting solutions for 46 cases...\n",
            "‚úÖ Loaded metadata for 46 cases\n",
            "‚úÖ Extracted 46 solutions\n",
            "   case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_631_Pid_Sus_2023_PN_JKT_TIM_Tanggal_14_Desember_2023__Penuntut_Umum_ANDI_JEFRI_ARDIN__S_H_Terdakwa_DIAN_YUDI_SAPUTRA_alias_ABU_HANIF_Bin_WAHYU_ILAHI__Alm: mengadili perkara pidana denganacara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan seb...\n",
            "   case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_629_Pid_Sus_2023_PN_JKT_TIM_Tanggal_14_Desember_2023__Penuntut_Umum_HERRY_WIYANTO__SH__M_HumTerdakwa_TAJUDIN_Als_PAK_HAJI_TAJUDIN_Als_PAK_TEJE_Als_PAKWA_URA: mengadili perkara pidana denganacara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan seb...\n",
            "   case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_555_Pid_Sus_2023_PN_JKT_TIM_Tanggal_13_Desember_2023__Penuntut_Umum_ERWIN_INDRAPUTRA__SH___MHTerdakwa_ARIS_BUDIANTO_alias_RIKO_alias_BAHAR_alias_SARAHARSONO: mengadili perkara pidana denganacara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan seb...\n",
            "‚úÖ Cached 46 solutions\n",
            "üîÆ ii. ALGORITMA PREDIKSI\n",
            "üß™ iv. DEMO MANUAL\n",
            "üìä v. OUTPUT\n",
            "\n",
            "üîÆ Running complete solution reuse process...\n",
            "\n",
            "==================================================\n",
            "üß™ iv. DEMO MANUAL\n",
            "==================================================\n",
            "üìù Created 5 demo cases\n",
            "   DEMO_001: Peledakan bom di fasilitas umum\n",
            "   DEMO_002: Perencanaan serangan terhadap aparat\n",
            "   DEMO_003: Radikalisasi generasi muda\n",
            "   DEMO_004: Pendanaan terorisme lintas negara\n",
            "   DEMO_005: Penggerebekan dan penangkapan\n",
            "\n",
            "üîÆ Running prediction demo...\n",
            "\n",
            "--- DEMO_001 ---\n",
            "Query: aksi terorisme dengan peledakan bom di terminal bus kota\n",
            "Expected: Terbukti bersalah, pidana penjara seumur hidup\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: mengadili perkara pidana denganacara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan seb...\n",
            "  Confidence: 0.073\n",
            "  Top cases: ['case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_555_Pid_Sus_2023_PN_JKT_TIM_Tanggal_13_Desember_2023__Penuntut_Umum_ERWIN_INDRAPUTRA__SH___MHTerdakwa_ARIS_BUDIANTO_alias_RIKO_alias_BAHAR_alias_SARAHARSONO', 'case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_545_Pid_Sus_2023_PN_JKT_TIM_Tanggal_11_Oktober_2023__Penuntut_Umum_MALINI_SIANTURI__SHTerdakwa_DIKA_GARNAKA_alias_HAMZAH_alias_ABU_USAMAH_alias_PEMBURA__Alm', 'case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_544_Pid_Sus_2023_PN_JKT_TIM_Tanggal_13_Nopember_2023__Penuntut_Umum_MALINI_SIANTURI__SHTerdakwa_MUHAMMAD_BUDI_SATRIA_Alias_BUDI__alias_KARI__alias_JUNH__Alm']\n",
            "  Match score: 0.20\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: mengadili perkara pidana denganacara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan seb...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_555_Pid_Sus_2023_PN_JKT_TIM_Tanggal_13_Desember_2023__Penuntut_Umum_ERWIN_INDRAPUTRA__SH___MHTerdakwa_ARIS_BUDIANTO_alias_RIKO_alias_BAHAR_alias_SARAHARSONO', 'case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_545_Pid_Sus_2023_PN_JKT_TIM_Tanggal_11_Oktober_2023__Penuntut_Umum_MALINI_SIANTURI__SHTerdakwa_DIKA_GARNAKA_alias_HAMZAH_alias_ABU_USAMAH_alias_PEMBURA__Alm', 'case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_544_Pid_Sus_2023_PN_JKT_TIM_Tanggal_13_Nopember_2023__Penuntut_Umum_MALINI_SIANTURI__SHTerdakwa_MUHAMMAD_BUDI_SATRIA_Alias_BUDI__alias_KARI__alias_JUNH__Alm']\n",
            "  Match score: 0.20\n",
            "\n",
            "--- DEMO_002 ---\n",
            "Query: penangkapan anggota kelompok teroris yang merencanakan serangan terhadap aparat\n",
            "Expected: Terbukti bersalah, pidana penjara\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: amar putusan dibawah ini;menimbang, bahwa oleh karena terdakwa dijatuhi pidana danterdakwa sebelumny...\n",
            "  Confidence: 0.057\n",
            "  Top cases: ['case_2023_TK1_Putusan_PN_JAKARTA_BARAT_Nomor_8_Pid_Sus_2023_PN_Jkt_Brt_Tanggal_13_April_2023__Penuntut_Umum_1_ANDI_JEFRI_ARDIN__SH_MH2_JAHRUDIN__SH3_DENRI_KASWORO__S_H_4_ZULKIFLI__SH__MH5_KHAREZA_SOLEH', 'case_2023_TK1_Putusan_PN_JAKARTA_BARAT_Nomor_1160_Pid_Sus_2022_PN_Jkt_Brt_Tanggal_30_Maret_2023__Penuntut_Umum_1_SUHARTATI__SH__MH2_MALINI_SIANTURI_SH3_Dr__HERRY_WIYANTO__SH_M_Hum4_NURHAYATI_ULFIAN_ALM', 'case_2023_TK1_Putusan_PN_JAKARTA_BARAT_Nomor_1107_Pid_Sus_2022_PN_Jkt_Brt_Tanggal_16_Maret_2023__Penuntut_Umum_1_ARIF_SUSANTO__SH__MH2_ARY_PRATAMA__SH3_AMRI_BAYAKTA__S_H_4_MUHAMAD_RAMLI__SH5_WULA_WARNO']\n",
            "  Match score: 0.20\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: mengadili perkara pidana denganacara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan seb...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2023_TK1_Putusan_PN_JAKARTA_BARAT_Nomor_8_Pid_Sus_2023_PN_Jkt_Brt_Tanggal_13_April_2023__Penuntut_Umum_1_ANDI_JEFRI_ARDIN__SH_MH2_JAHRUDIN__SH3_DENRI_KASWORO__S_H_4_ZULKIFLI__SH__MH5_KHAREZA_SOLEH', 'case_2023_TK1_Putusan_PN_JAKARTA_BARAT_Nomor_1160_Pid_Sus_2022_PN_Jkt_Brt_Tanggal_30_Maret_2023__Penuntut_Umum_1_SUHARTATI__SH__MH2_MALINI_SIANTURI_SH3_Dr__HERRY_WIYANTO__SH_M_Hum4_NURHAYATI_ULFIAN_ALM', 'case_2023_TK1_Putusan_PN_JAKARTA_BARAT_Nomor_1107_Pid_Sus_2022_PN_Jkt_Brt_Tanggal_16_Maret_2023__Penuntut_Umum_1_ARIF_SUSANTO__SH__MH2_ARY_PRATAMA__SH3_AMRI_BAYAKTA__S_H_4_MUHAMAD_RAMLI__SH5_WULA_WARNO']\n",
            "  Match score: 0.20\n",
            "\n",
            "--- DEMO_003 ---\n",
            "Query: radikalisasi mahasiswa melalui media sosial oleh jaringan teror\n",
            "Expected: Terbukti bersalah, pidana penjara dan rehabilitasi\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: mengadili perkara pidana denganacara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan seb...\n",
            "  Confidence: 0.024\n",
            "  Top cases: ['case_2023_TK1_Putusan_PN_JAKARTA_BARAT_Nomor_1160_Pid_Sus_2022_PN_Jkt_Brt_Tanggal_30_Maret_2023__Penuntut_Umum_1_SUHARTATI__SH__MH2_MALINI_SIANTURI_SH3_Dr__HERRY_WIYANTO__SH_M_Hum4_NURHAYATI_ULFIAN_ALM', 'case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_73_Pid_Sus_2023_PN_Jkt_Tim_Tanggal_10_Mei_2023__Penuntut_Umum_HARDINIYANTY__SH__MHTerdakwa_LUKMAN_YUNUS_Als_UKO_Als_ABU_SYUKRON_Bin_IDAM_YUNUS', 'case_2025_TK1_Putusan_PA_TILAMUTA_Nomor_81_Pdt_P_2025_PA_Tlm_Tanggal_12_Juni_2025__Pemohon_melawan_Termohon']\n",
            "  Match score: 0.20\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: mengadili perkara pidana denganacara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan seb...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2023_TK1_Putusan_PN_JAKARTA_BARAT_Nomor_1160_Pid_Sus_2022_PN_Jkt_Brt_Tanggal_30_Maret_2023__Penuntut_Umum_1_SUHARTATI__SH__MH2_MALINI_SIANTURI_SH3_Dr__HERRY_WIYANTO__SH_M_Hum4_NURHAYATI_ULFIAN_ALM', 'case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_73_Pid_Sus_2023_PN_Jkt_Tim_Tanggal_10_Mei_2023__Penuntut_Umum_HARDINIYANTY__SH__MHTerdakwa_LUKMAN_YUNUS_Als_UKO_Als_ABU_SYUKRON_Bin_IDAM_YUNUS', 'case_2025_TK1_Putusan_PA_TILAMUTA_Nomor_81_Pdt_P_2025_PA_Tlm_Tanggal_12_Juni_2025__Pemohon_melawan_Termohon']\n",
            "  Match score: 0.20\n",
            "\n",
            "--- DEMO_004 ---\n",
            "Query: pengiriman dana dari luar negeri untuk mendanai aksi teror di indonesia\n",
            "Expected: Terbukti bersalah, pidana penjara dan perampasan dana\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: mengadili perkara pidana denganacara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan seb...\n",
            "  Confidence: 0.049\n",
            "  Top cases: ['case_2023_TK1_Putusan_PN_JAKARTA_BARAT_Nomor_1160_Pid_Sus_2022_PN_Jkt_Brt_Tanggal_30_Maret_2023__Penuntut_Umum_1_SUHARTATI__SH__MH2_MALINI_SIANTURI_SH3_Dr__HERRY_WIYANTO__SH_M_Hum4_NURHAYATI_ULFIAN_ALM', 'case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_73_Pid_Sus_2023_PN_Jkt_Tim_Tanggal_10_Mei_2023__Penuntut_Umum_HARDINIYANTY__SH__MHTerdakwa_LUKMAN_YUNUS_Als_UKO_Als_ABU_SYUKRON_Bin_IDAM_YUNUS', 'case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_71_Pid_Sus_2023_PN_Jkt_Tim_Tanggal_17_Mei_2023__Penuntut_Umum_TEDDY_IRAWAN___SH___MH_Terdakwa_HERLIANSYAH_als_ANDI_BASO_als_HERLY_BIN_SULTANNI']\n",
            "  Match score: 0.20\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: mengadili perkara pidana denganacara pemeriksaan biasa dalam tingkat pertama menjatuhkan putusan seb...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2023_TK1_Putusan_PN_JAKARTA_BARAT_Nomor_1160_Pid_Sus_2022_PN_Jkt_Brt_Tanggal_30_Maret_2023__Penuntut_Umum_1_SUHARTATI__SH__MH2_MALINI_SIANTURI_SH3_Dr__HERRY_WIYANTO__SH_M_Hum4_NURHAYATI_ULFIAN_ALM', 'case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_73_Pid_Sus_2023_PN_Jkt_Tim_Tanggal_10_Mei_2023__Penuntut_Umum_HARDINIYANTY__SH__MHTerdakwa_LUKMAN_YUNUS_Als_UKO_Als_ABU_SYUKRON_Bin_IDAM_YUNUS', 'case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_71_Pid_Sus_2023_PN_Jkt_Tim_Tanggal_17_Mei_2023__Penuntut_Umum_TEDDY_IRAWAN___SH___MH_Terdakwa_HERLIANSYAH_als_ANDI_BASO_als_HERLY_BIN_SULTANNI']\n",
            "  Match score: 0.20\n",
            "\n",
            "--- DEMO_005 ---\n",
            "Query: penggerebekan tempat persembunyian kelompok teroris oleh densus 88\n",
            "Expected: Penangkapan berhasil, proses hukum berjalan\n",
            "\n",
            "WEIGHTED Method:\n",
            "  Predicted: mengadili perkara pidanadengan acara pemeriksaan biasa dalam tingkat pertama menjatuhkanputusan seba...\n",
            "  Confidence: 0.051\n",
            "  Top cases: ['case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_71_Pid_Sus_2023_PN_Jkt_Tim_Tanggal_17_Mei_2023__Penuntut_Umum_TEDDY_IRAWAN___SH___MH_Terdakwa_HERLIANSYAH_als_ANDI_BASO_als_HERLY_BIN_SULTANNI', 'case_2023_TK1_Putusan_PN_JAKARTA_BARAT_Nomor_1160_Pid_Sus_2022_PN_Jkt_Brt_Tanggal_30_Maret_2023__Penuntut_Umum_1_SUHARTATI__SH__MH2_MALINI_SIANTURI_SH3_Dr__HERRY_WIYANTO__SH_M_Hum4_NURHAYATI_ULFIAN_ALM', 'case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_629_Pid_Sus_2023_PN_JKT_TIM_Tanggal_14_Desember_2023__Penuntut_Umum_HERRY_WIYANTO__SH__M_HumTerdakwa_TAJUDIN_Als_PAK_HAJI_TAJUDIN_Als_PAK_TEJE_Als_PAKWA_URA']\n",
            "  Match score: 0.00\n",
            "\n",
            "MAJORITY Method:\n",
            "  Predicted: mengadili perkara pidanadengan acara pemeriksaan biasa dalam tingkat pertama menjatuhkanputusan seba...\n",
            "  Confidence: 1.000\n",
            "  Top cases: ['case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_71_Pid_Sus_2023_PN_Jkt_Tim_Tanggal_17_Mei_2023__Penuntut_Umum_TEDDY_IRAWAN___SH___MH_Terdakwa_HERLIANSYAH_als_ANDI_BASO_als_HERLY_BIN_SULTANNI', 'case_2023_TK1_Putusan_PN_JAKARTA_BARAT_Nomor_1160_Pid_Sus_2022_PN_Jkt_Brt_Tanggal_30_Maret_2023__Penuntut_Umum_1_SUHARTATI__SH__MH2_MALINI_SIANTURI_SH3_Dr__HERRY_WIYANTO__SH_M_Hum4_NURHAYATI_ULFIAN_ALM', 'case_2023_TK1_Putusan_PN_JAKARTA_TIMUR_Nomor_629_Pid_Sus_2023_PN_JKT_TIM_Tanggal_14_Desember_2023__Penuntut_Umum_HERRY_WIYANTO__SH__M_HumTerdakwa_TAJUDIN_Als_PAK_HAJI_TAJUDIN_Als_PAK_TEJE_Als_PAKWA_URA']\n",
            "  Match score: 0.00\n",
            "\n",
            "==================================================\n",
            "üìä v. OUTPUT\n",
            "==================================================\n",
            "üìÑ Predictions saved: predictions_20250626_073040.csv\n",
            "   Records: 10\n",
            "   Columns: ['query_id', 'query', 'method', 'predicted_solution', 'expected_outcome', 'top_5_case_ids', 'confidence', 'match_score', 'match_explanation']\n",
            "üìÑ Detailed results saved: detailed_predictions_20250626_073040.json\n",
            "\n",
            "======================================================================\n",
            "üîÆ TAHAP 4 - SOLUTION REUSE - SUMMARY REPORT\n",
            "======================================================================\n",
            "Generated: 2025-06-26 07:30:40\n",
            "\n",
            "üìä OVERALL STATISTICS:\n",
            "  Total predictions: 10\n",
            "  Successful predictions: 10 (100.0%)\n",
            "  Average confidence: 0.525\n",
            "  Average match score: 0.160\n",
            "\n",
            "üîß METHOD COMPARISON:\n",
            "  MAJORITY:\n",
            "    Avg Confidence: 1.000\n",
            "    Avg Match Score: 0.160\n",
            "  WEIGHTED:\n",
            "    Avg Confidence: 0.051\n",
            "    Avg Match Score: 0.160\n",
            "\n",
            "üèÜ BEST PREDICTIONS:\n",
            "  1. DEMO_001 (weighted)\n",
            "     Query: aksi terorisme dengan peledakan bom di terminal bu...\n",
            "     Match Score: 0.200\n",
            "     Confidence: 0.073\n",
            "  2. DEMO_001 (majority)\n",
            "     Query: aksi terorisme dengan peledakan bom di terminal bu...\n",
            "     Match Score: 0.200\n",
            "     Confidence: 1.000\n",
            "  3. DEMO_002 (weighted)\n",
            "     Query: penangkapan anggota kelompok teroris yang merencan...\n",
            "     Match Score: 0.200\n",
            "     Confidence: 0.057\n",
            "\n",
            "‚ùå POOR: System requires significant work\n",
            "======================================================================\n",
            "\n",
            "============================================================\n",
            "‚úÖ TAHAP 4 - SOLUTION REUSE COMPLETED!\n",
            "üìÅ Output files created:\n",
            "   - predictions_20250626_073040.csv\n",
            "   - detailed_predictions_20250626_073040.json\n",
            "üîÆ Solution reuse system ready for production!\n",
            "============================================================\n",
            "\n",
            "üéâ TAHAP 4 BERHASIL!\n",
            "‚ú® Yang telah diselesaikan:\n",
            "  ‚úÖ i. Ekstrak Solusi dari kasus top-k\n",
            "  ‚úÖ ii. Algoritma Prediksi (majority vote & weighted similarity)\n",
            "  ‚úÖ iii. Implementasi Fungsi predict_outcome()\n",
            "  ‚úÖ iv. Demo Manual dengan 5 contoh kasus\n",
            "  ‚úÖ v. Output CSV dan JSON hasil prediksi\n",
            "üîÆ Solution reuse system siap digunakan!\n"
          ]
        }
      ]
    }
  ]
}